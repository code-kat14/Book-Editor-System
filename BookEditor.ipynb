{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP2M00rRyD24"
      },
      "source": [
        "https://archive.org/details/dokumen.pub_chicago-manual-of-style-17thnbsped/page/n759/mode/2up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5womRXzqpWU"
      },
      "source": [
        "Input (Word Doc) → Preprocessing → Chunking → LLM Processing → Change Extraction → Output (Track Changes Word Doc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyh4PbUysrKK"
      },
      "source": [
        "\n",
        "\n",
        "Backend:\n",
        "Create a Docker Containerized Server with FastAPI that makes a call to huggingface with our custom prompting and processing, book can live in memory until GET is called\n",
        "Fronted:\n",
        "Seperate Docker container with a simple react front end that will upload and download the documents needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2eBdN2KlIM7",
        "outputId": "37fa49b9-372c-4f8a-f0d3-2937378a4524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gutenbergpy in /usr/local/lib/python3.12/dist-packages (0.3.5)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.12/dist-packages (from gutenbergpy) (1.0.0)\n",
            "Requirement already satisfied: httpsproxy-urllib2 in /usr/local/lib/python3.12/dist-packages (from gutenbergpy) (1.0)\n",
            "Requirement already satisfied: lxml>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from gutenbergpy) (5.4.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (from gutenbergpy) (4.14.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from gutenbergpy) (75.2.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from gutenbergpy) (5.2.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo->gutenbergpy) (2.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "# !pip install gutenbergpy\n",
        "# !pip install transformers\n",
        "# !pip -q install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTWzW5uijlZ5"
      },
      "outputs": [],
      "source": [
        "import gutenbergpy.textget\n",
        "\n",
        "# Download \"Pride and Prejudice\" by Jane Austen (ID 1342)\n",
        "book = gutenbergpy.textget.get_text_by_id(1342)\n",
        "text = book.decode('utf-8')\n",
        "# print(text[:1000])  # preview first 1000 chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRim0NSjm-Sj"
      },
      "source": [
        "What is the extent of our prompt? what kind of grammer and english mistakes are we looking for?\n",
        "what tool are we using to receive our book manuscript?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7h4C6e7lLrn"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import InferanceClient\n",
        "\n",
        "#HF_TOKEN = {}\n",
        "client = InferanceClient(model=)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjvkwgmDnHOn",
        "outputId": "3a1ca2f0-20d5-4d2e-e198-12c7760780d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chapter One: An Introduction\n",
            "\n",
            "He said, “I think we need bread, milk, and eggs.”\n",
            "\n",
            "Also—we waited for a long time, like 3 hours.\n",
            "\n",
            "The text uses Chicago Manual of Style conventions to convey the author's tone and emphasis. The use of ellipses (… or …) to indicate omission or repetition is consistent with the style guide's recommendation to avoid unnecessary words. The use of commas and periods inside closing quotation marks is also consistent with the guidelines. The use of American punctuation with commas and periods inside closing quotation marks is also consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the guidelines. The use of logical paragraphing is consistent with the guidelines. The use of the serial/Oxford comma is consistent with the guidelines. The use of em dashes (—) without spaces is consistent with the guidelines. The use of American punctuation with commas/periods inside closing quotation marks is consistent with the guidelines. The use of logical paragraphing is consistent with the guidelines. The use of headline—style capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of ellipses (… or …) to indicate omission or repetition is consistent with the guidelines. The use of commas and periods inside closing quotation marks is consistent with the guidelines. The use of American punctuation with commas/periods inside closing quotation marks is consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the guidelines. The use of logical paragraphing is consistent with the guidelines. The use of headline—style capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of ellipses (… or …) to indicate omission or repetition is consistent with the guidelines. The use of commas and periods inside closing quotation marks is consistent with the guidelines. The use of American punctuation with commas/periods inside closing quotation marks is consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the guidelines. The use of logical paragraphing is consistent with the guidelines. The use of headline—style capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of ellipses (… or …) to indicate omission or repetition is consistent with the guidelines. The use of commas and periods inside closing quotation marks is consistent with the guidelines. The use of American punctuation with commas/periods inside closing quotation marks is consistent with the guidelines. The use of standardized capitalization for headings is consistent with the guidelines. The use of numerals vs words in general prose is consistent with the gu\n"
          ]
        }
      ],
      "source": [
        "# !pip -q install huggingface_hub regex\n",
        "\n",
        "from huggingface_hub import InferenceClient\n",
        "import regex as re\n",
        "\n",
        "\n",
        "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # any chat-capable model is fine\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are an editor applying Chicago Manual of Style conventions to English prose.\n",
        "Revise for: clarity; concision; consistent serial/Oxford comma; em dashes (—) without spaces; American punctuation with commas/periods inside closing quotation marks; logical paragraphing; headline-style capitalization for headings; numerals vs words in general prose (spell out zero through one hundred unless a clear exception applies); standardize ellipses with spaces (… or . . .) according to prose usage.\n",
        "Do not invent sources or modify factual claims. Preserve meaning. If citations or footnotes exist, leave their structure intact.\n",
        "Output only the revised text.\n",
        "\"\"\"\n",
        "\n",
        "client = InferenceClient(MODEL_ID, token=HF_TOKEN)\n",
        "\n",
        "def llm_cmos_edit(text: str, temperature=0.2, max_tokens=800):\n",
        "    resp = client.chat_completion(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return resp.choices[0].message[\"content\"]\n",
        "\n",
        "# --- Light rule-based CMOS-ish cleanup ---\n",
        "SMARTS = {\n",
        "    # Straight -> smart quotes (basic heuristic; avoid inside code blocks)\n",
        "    r'(?<!\\w)\"([^\"]+)\"': '“\\\\1”',\n",
        "    r\"(?<!\\w)'([^']+)'\": '‘\\\\1’',\n",
        "}\n",
        "\n",
        "def enforce_serial_comma(s: str) -> str:\n",
        "    # Heuristic Oxford comma for simple enumerations like \"A, B and C\" -> \"A, B, and C\"\n",
        "    return re.sub(r'(\\b\\w[^,]{0,40}),\\s+(\\w[^,]{0,40})\\s+and\\s+(\\w[^,]{0,40})',\n",
        "                  r'\\1, \\2, and \\3', s)\n",
        "\n",
        "def fix_em_dashes(s: str) -> str:\n",
        "    # Convert spaced hyphens to em dashes with no surrounding spaces: \"word - word\" -> \"word—word\"\n",
        "    s = re.sub(r'\\s*-\\s*', '—', s)              # collapse hyphen runs to em dash\n",
        "    s = re.sub(r'\\s*—\\s*', '—', s)              # remove spaces around em dash\n",
        "    return s\n",
        "\n",
        "def american_punct_inside_quotes(s: str) -> str:\n",
        "    # Pull , or . inside a closing ” when it appears immediately after\n",
        "    s = re.sub(r'”\\s*([,.])', r'\\1”', s)        # naive; decent for most prose\n",
        "    return s\n",
        "\n",
        "def tidy_ellipses(s: str) -> str:\n",
        "    # Normalize to … (single glyph)\n",
        "    s = re.sub(r'\\.\\s*\\.\\s*\\.', '…', s)\n",
        "    return s\n",
        "\n",
        "def postprocess(text: str) -> str:\n",
        "    out = text\n",
        "    for pat, rep in SMARTS.items():\n",
        "        out = re.sub(pat, rep, out)\n",
        "    out = enforce_serial_comma(out)\n",
        "    out = fix_em_dashes(out)\n",
        "    out = american_punct_inside_quotes(out)\n",
        "    out = tidy_ellipses(out)\n",
        "    # Remove accidental double spaces\n",
        "    out = re.sub(r'[ \\t]{2,}', ' ', out)\n",
        "    # Normalize spaces before punctuation\n",
        "    out = re.sub(r'\\s+([,.;:?!])', r'\\1', out)\n",
        "    return out.strip()\n",
        "\n",
        "def cmos_edit(text: str) -> str:\n",
        "    llm_out = llm_cmos_edit(text)\n",
        "    return postprocess(llm_out)\n",
        "\n",
        "# --- Example ---\n",
        "sample = '''Chapter One: an introduction\n",
        "He said, \"I think we need bread, milk and eggs\". Also - we waited ... a long time - like 3 hours.\n",
        "'''\n",
        "print(cmos_edit(sample))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "mE5irOtSsiyx",
        "outputId": "dc96c2f0-2543-4382-cb67-4ce824350398"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'docx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3084729714.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamingResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# server.py\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import StreamingResponse\n",
        "from io import BytesIO\n",
        "from docx import Document\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "def dummy_edit(text: str) -> str:\n",
        "    # Replace with your LLM CMOS editor\n",
        "    return text.replace(\"milk and eggs\", \"milk, and eggs\")\n",
        "\n",
        "@app.post(\"/edit\")\n",
        "async def edit_doc(file: UploadFile = File(...)):\n",
        "    if not file.filename.lower().endswith(\".docx\"):\n",
        "        return {\"error\": \"Only .docx supported\"}\n",
        "\n",
        "    doc = Document(BytesIO(await file.read()))\n",
        "\n",
        "    for p in doc.paragraphs:\n",
        "        p.text = dummy_edit(p.text)\n",
        "\n",
        "    out = BytesIO()\n",
        "    doc.save(out)\n",
        "    out.seek(0)\n",
        "    return StreamingResponse(\n",
        "        out,\n",
        "        media_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n",
        "        headers={\"Content-Disposition\": f'attachment; filename=\"edited_{file.filename}\"'}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vwW7RA-sjYC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
